import os

def tokenize(sentence):
	return sentence.split(' ')
